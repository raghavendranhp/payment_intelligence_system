import os
import json
import requests
from dotenv import load_dotenv 
load_dotenv()  

class GroqAIService:
    def __init__(self):
        """
        Initializes the connection to Groq API.
        Expects GROQ_API_KEY to be set in the .env file.
        """
        self.api_key = os.getenv("GROQ_API_KEY")
        self.api_endpoint = "https://api.groq.com/openai/v1/chat/completions" 
        self.model = "llama-3.1-8b-instant" 

        # Dynamically locate the prompts directory
        self.prompts_dir = os.path.join(
            os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 
            "prompts"
        )

    def _load_prompt(self, filename: str) -> str:
        """Helper to read prompt text from the external files."""
        filepath = os.path.join(self.prompts_dir, filename)
        try:
            with open(filepath, "r", encoding="utf-8") as file:
                return file.read().strip()
        except FileNotFoundError:
            return f"Error: Required prompt file '{filename}' is missing."

    def _call_groq_api(self, user_prompt: str, system_context: str, response_format: str = "text") -> str:
        """
        Core method to communicate with Groq API using standard requests.
        """
        if not self.api_key:
            return '{"error": "GROQ_API_KEY is missing."}' if response_format == "json" else "Error: API Key missing."

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "messages": [
                {"role": "system", "content": system_context},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": 0.1
        }

        #Enforce strict JSON output if requested
        if response_format == "json":
            payload["response_format"] = {"type": "json_object"}
            # Groq/Llama requires the system prompt to explicitly mention "JSON"
            payload["messages"][0]["content"] += "\nYou MUST output your response strictly in JSON format."

        try:
            response = requests.post(self.api_endpoint, headers=headers, json=payload)
            response.raise_for_status() # Check for HTTP errors
            
            # Extract the text generated by the model
            return response.json()['choices'][0]['message']['content']
            
        except requests.exceptions.RequestException as e:
            print(f"API Connection Error: {e}")
            if hasattr(e, 'response') and e.response is not None:
                print(f"Error Details: {e.response.text}")
            return "{}" if response_format == "json" else "Failed to generate AI response."

    def generate_payment_summary(self, metrics: dict) -> str:
        system_context = self._load_prompt("summary_system.txt")
        user_template = self._load_prompt("summary_user.txt")
        
        prompt = f"{user_template}\n\nMetrics Data:\n{json.dumps(metrics, indent=2)}"
        return self._call_groq_api(prompt, system_context)

    def explain_fraud_risk(self, risk_data: dict) -> dict:
        system_context = self._load_prompt("fraud_system.txt")
        user_template = self._load_prompt("fraud_user.txt")
        
        prompt = f"{user_template}\n\nTransaction Data:\n{json.dumps(risk_data, indent=2)}"
        
        #We enforce response_format="json" here so Groq returns a parseable dictionary
        ai_response_str = self._call_groq_api(prompt, system_context, response_format="json")
        
        try:
            ai_data = json.loads(ai_response_str)
            return {
                "risk_score": risk_data.get('heuristic_risk_score', 'Unknown'),
                "explanation": ai_data.get("explanation", "No explanation provided."),
                "recommendation": ai_data.get("recommendation", "review")
            }
        except json.JSONDecodeError:
            return {
                "risk_score": risk_data.get('heuristic_risk_score', 'Unknown'),
                "explanation": "Failed to parse the AI's JSON output.",
                "recommendation": "review"
            }

    def answer_payment_query(self, question: str, global_context: dict) -> str:
        system_context = self._load_prompt("query_system.txt")
        
        
        prompt = f"System Context Data:\n{json.dumps(global_context, indent=2)}\n\nUser Question: {question}"
        return self._call_groq_api(prompt, system_context)

    def generate_recommendations(self, global_context: dict) -> str:
        system_context = self._load_prompt("recommendation_system.txt")
        user_template = self._load_prompt("recommendation_user.txt")
        
        prompt = f"{user_template}\n\nGlobal Metrics:\n{json.dumps(global_context, indent=2)}"
        return self._call_groq_api(prompt, system_context)